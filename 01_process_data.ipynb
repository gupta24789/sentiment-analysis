{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0sZPJFtPAnSx7A3NYbOqu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta24789/sentiment-analysis/blob/main/01_process_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzXlk6nlShYq",
        "outputId": "9d022db2-b55f-43d7-cca2-36f7a48cb1e1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Data"
      ],
      "metadata": {
        "id": "UgMbF9HZYEm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_tweets_url = \"https://raw.githubusercontent.com/gupta24789/Machine-Learning-Datasets/master/twitter_samples/positive_tweets.json\"\n",
        "negative_tweets_url = \"https://raw.githubusercontent.com/gupta24789/Machine-Learning-Datasets/master/twitter_samples/negative_tweets.json\"\n",
        "\n",
        "positive_tweets  = pd.read_json(positive_tweets_url)['positive_tweets'].tolist()\n",
        "negative_tweets  = pd.read_json(negative_tweets_url)['negative_tweets'].tolist()"
      ],
      "metadata": {
        "id": "UfYaPeHtUJbZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_tweets[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfTnL5FRYzBN",
        "outputId": "bd953087-1582-44d7-e15d-f43df8aa62e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
              " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!',\n",
              " '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_tweets[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDbuiFfHY0x6",
        "outputId": "4488d021-0c9f-479d-b0cd-3a6289c252b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hopeless for tmr :(',\n",
              " \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in 2 months :(\",\n",
              " '@Hegelbon That heart sliding into the waste basket. :(']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process the Data"
      ],
      "metadata": {
        "id": "hbY-hNR7YhEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tweet(tweet):\n",
        "    \"\"\"Process tweet function.\n",
        "    Input:\n",
        "        tweet: a string containing a tweet\n",
        "    Output:\n",
        "        tweets_clean: a list of words containing the processed tweet\n",
        "\n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in string.punctuation):  # remove punctuation\n",
        "            # tweets_clean.append(word)\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean"
      ],
      "metadata": {
        "id": "U3oLGa7SXICl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_tweets_list = []\n",
        "for tweet in positive_tweets:\n",
        "  positive_tweets_list.append({\n",
        "      \"raw_tweet\": tweet,\n",
        "      \"processed_tweet\": process_tweet(tweet),\n",
        "      \"label\": 1\n",
        "  })"
      ],
      "metadata": {
        "id": "3M2ZKyB5XVe4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_tweets_list = []\n",
        "for tweet in negative_tweets:\n",
        "  negative_tweets_list.append({\n",
        "      \"raw_tweet\": tweet,\n",
        "      \"processed_tweet\": process_tweet(tweet),\n",
        "      \"label\": 0\n",
        "  })"
      ],
      "metadata": {
        "id": "ea8XIOHHZyO9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Positive : {len(positive_tweets_list)}\\nNegative : {len(negative_tweets_list)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0YD9Gd8a1Wc",
        "outputId": "983aaa8a-bea1-4e60-9528-b66454941d2f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive : 5000\n",
            "Negative : 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_list = list(range(0, len(positive_tweets_list)))\n",
        "random.shuffle(index_list)\n",
        "\n",
        "train_size = int(0.8 * 5000)\n",
        "train_index = index_list[:train_size]\n",
        "val_index = index_list[train_size:]"
      ],
      "metadata": {
        "id": "hKVQDNeAbNl6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = [positive_tweets_list[i] for i in train_index] + [negative_tweets_list[i] for i in train_index]\n",
        "val = [positive_tweets_list[i] for i in val_index] + [negative_tweets_list[i] for i in val_index]"
      ],
      "metadata": {
        "id": "ny1stkLobqjs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train), len(val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1kVh1Ulcyef",
        "outputId": "b61e12f5-dbd5-4b7f-987e-32b7aff27ced"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame(train)\n",
        "val_df = pd.DataFrame(val)"
      ],
      "metadata": {
        "id": "ZTtKIOrNc0ed"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_C7ymd7c2fI",
        "outputId": "c74bf2b9-6590-4409-9a63-9de6cb46374b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4000\n",
              "0    4000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5Bi_KUidNNh",
        "outputId": "2f048cad-350c-4bc1-e361-8e23aa4de998"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1000\n",
              "0    1000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"data/train.csv\", index = False)\n",
        "val_df.to_csv(\"data/val.csv\", index = False)"
      ],
      "metadata": {
        "id": "53Gs_wECdkhS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQgk3SgBdyiI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}